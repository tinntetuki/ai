#!/usr/bin/env python3
"""
Example usage of the text-to-speech functionality
"""

import asyncio
import os
from pathlib import Path
from src.ai_engine.tts_processor import create_tts_processor, VoiceProfile
from src.ai_engine.speech_processor import create_speech_processor


async def example_basic_tts():
    """Basic text-to-speech example"""

    print("ğŸ”Š Basic Text-to-Speech Example")
    print("=" * 40)

    # Create TTS processor
    tts_processor = create_tts_processor()

    # Chinese text example
    chinese_text = "æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„äº§å“å±•ç¤ºï¼è¿™æ¬¾äº§å“å…·æœ‰å‡ºè‰²çš„æ€§èƒ½å’Œä¼˜è´¨çš„å“è´¨ï¼Œç°åœ¨è´­ä¹°è¿˜èƒ½äº«å—ç‰¹åˆ«ä¼˜æƒ ã€‚"

    # Create Chinese voice profile
    chinese_voice = VoiceProfile(
        provider="edge",
        voice_name="zh-CN-XiaoxiaoNeural",
        language="zh-CN",
        gender="female",
        style="friendly",
        speed=1.0,
        pitch=1.0,
        volume=1.0
    )

    # Synthesize Chinese
    chinese_output = "output_chinese.wav"
    await tts_processor.synthesize_text(
        text=chinese_text,
        voice_profile=chinese_voice,
        output_path=chinese_output
    )

    print(f"âœ… Chinese TTS completed: {chinese_output}")

    # English text example
    english_text = "Welcome to our amazing product showcase! This item features excellent performance and premium quality. Buy now for special discounts!"

    # Create English voice profile
    english_voice = VoiceProfile(
        provider="edge",
        voice_name="en-US-JennyNeural",
        language="en-US",
        gender="female",
        style="professional",
        speed=0.95,
        pitch=1.0,
        volume=1.0
    )

    # Synthesize English
    english_output = "output_english.wav"
    await tts_processor.synthesize_text(
        text=english_text,
        voice_profile=english_voice,
        output_path=english_output
    )

    print(f"âœ… English TTS completed: {english_output}")


async def example_voice_styles():
    """Demonstrate different voice styles for product videos"""

    print("\nğŸ­ Voice Styles Example")
    print("=" * 40)

    tts_processor = create_tts_processor()

    product_text = "è¿™æ˜¯ä¸€æ¬¾é©å‘½æ€§çš„äº§å“ï¼Œé‡‡ç”¨æœ€æ–°æŠ€æœ¯ï¼Œä¸ºæ‚¨å¸¦æ¥å‰æ‰€æœªæœ‰çš„ä½“éªŒã€‚ç«‹å³è´­ä¹°ï¼Œäº«å—é™æ—¶ä¼˜æƒ ï¼"

    styles = [
        ("professional", "ä¸“ä¸šé£æ ¼", "calm"),
        ("friendly", "å‹å¥½é£æ ¼", "friendly"),
        ("energetic", "å……æ»¡æ´»åŠ›", "excited"),
    ]

    for style_name, chinese_name, edge_style in styles:
        print(f"\nğŸ¤ {chinese_name} ({style_name})")

        # Create voice profile for each style
        voice_profile = tts_processor.create_product_voice_profile(
            language="zh",
            voice_type=style_name,
            gender="female"
        )

        output_path = f"product_{style_name}.wav"

        await tts_processor.synthesize_text(
            text=product_text,
            voice_profile=voice_profile,
            output_path=output_path
        )

        print(f"  âœ… Generated: {output_path}")


async def example_voiceover_replacement():
    """Replace video audio with new voiceover"""

    print("\nğŸ¬ Voiceover Replacement Example")
    print("=" * 40)

    # Input video path (replace with your actual video)
    input_video = "path/to/your/input_video.mp4"
    output_video = "path/to/your/output_with_voiceover.mp4"

    if not os.path.exists(input_video):
        print(f"âš ï¸ Video file not found: {input_video}")
        print("Please update the path to your actual video file")
        return

    try:
        # Create processors
        speech_processor = create_speech_processor(model_size="base")
        tts_processor = create_tts_processor()

        print("ğŸ“ Step 1: Transcribing original video...")

        # Transcribe original video
        transcription = speech_processor.transcribe_video(input_video)

        print(f"Original language: {transcription.language}")
        print(f"Duration: {transcription.duration:.2f} seconds")
        print(f"Segments: {len(transcription.segments)}")

        print("\nğŸ¤ Step 2: Creating new voiceover...")

        # Create professional Chinese female voice
        voice_profile = tts_processor.create_product_voice_profile(
            language="zh",
            voice_type="professional",
            gender="female"
        )

        # Create voiceover audio
        audio_output = "new_voiceover.wav"
        await tts_processor.create_voiceover_from_transcription(
            transcription=transcription,
            voice_profile=voice_profile,
            output_path=audio_output,
            preserve_timing=True,
            add_pauses=True
        )

        print(f"âœ… Voiceover audio created: {audio_output}")

        print("\nğŸ¬ Step 3: Replacing video audio...")

        # Replace video audio
        success = await tts_processor.replace_video_audio(
            video_path=input_video,
            new_audio_path=audio_output,
            output_path=output_video,
            fade_duration=0.5
        )

        if success:
            print(f"âœ… Video with new voiceover: {output_video}")
        else:
            print("âŒ Failed to replace video audio")

    except Exception as e:
        print(f"âŒ Error: {e}")


async def example_multilingual_voiceover():
    """Create voiceovers in multiple languages"""

    print("\nğŸŒ Multilingual Voiceover Example")
    print("=" * 40)

    tts_processor = create_tts_processor()

    # Product description in multiple languages
    texts = {
        "zh-CN": "è¿™æ¬¾äº§å“é‡‡ç”¨å…ˆè¿›æŠ€æœ¯ï¼Œä¸ºæ‚¨æä¾›å“è¶Šçš„ç”¨æˆ·ä½“éªŒã€‚ç°åœ¨è´­ä¹°äº«å—ç‰¹åˆ«æŠ˜æ‰£ï¼",
        "en-US": "This product uses advanced technology to provide you with an exceptional user experience. Buy now for special discounts!",
        "ja-JP": "ã“ã®è£½å“ã¯å…ˆé€²æŠ€è¡“ã‚’ä½¿ç”¨ã—ã€å„ªã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚ä»Šã™ãè³¼å…¥ã—ã¦ç‰¹åˆ¥å‰²å¼•ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ï¼",
        "ko-KR": "ì´ ì œí’ˆì€ ì²¨ë‹¨ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ë›°ì–´ë‚œ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì§€ê¸ˆ êµ¬ë§¤í•˜ì‹œë©´ íŠ¹ë³„ í• ì¸ í˜œíƒì„ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    }

    # Voice configurations for different languages
    voices = {
        "zh-CN": ("zh-CN-XiaoxiaoNeural", "female"),
        "en-US": ("en-US-JennyNeural", "female"),
        "ja-JP": ("ja-JP-NanamiNeural", "female"),
        "ko-KR": ("ko-KR-SunHiNeural", "female")
    }

    for lang_code, text in texts.items():
        print(f"\nğŸ¤ Creating {lang_code} voiceover...")

        voice_name, gender = voices[lang_code]

        voice_profile = VoiceProfile(
            provider="edge",
            voice_name=voice_name,
            language=lang_code,
            gender=gender,
            style="friendly",
            speed=1.0,
            pitch=1.0,
            volume=1.0
        )

        output_path = f"product_description_{lang_code}.wav"

        await tts_processor.synthesize_text(
            text=text,
            voice_profile=voice_profile,
            output_path=output_path
        )

        print(f"  âœ… {lang_code} voiceover: {output_path}")


async def example_batch_voiceover_generation():
    """Generate voiceovers for multiple product descriptions"""

    print("\nğŸ“ Batch Voiceover Generation Example")
    print("=" * 40)

    tts_processor = create_tts_processor()

    # Product descriptions for different items
    products = [
        {
            "name": "æ™ºèƒ½æ‰‹æœº",
            "description": "å…¨æ–°æ™ºèƒ½æ‰‹æœºï¼Œé…å¤‡æœ€æ–°å¤„ç†å™¨å’Œé«˜æ¸…æ‘„åƒå¤´ï¼Œä¸ºæ‚¨å¸¦æ¥æè‡´ä½“éªŒã€‚é™æ—¶ç‰¹æƒ ï¼Œç«‹å³æŠ¢è´­ï¼",
            "voice_type": "energetic"
        },
        {
            "name": "æ— çº¿è€³æœº",
            "description": "é«˜å“è´¨æ— çº¿è€³æœºï¼Œé™å™ªåŠŸèƒ½å‡ºè‰²ï¼ŒéŸ³è´¨æ¸…æ™°çº¯å‡€ã€‚é€‚åˆè¿åŠ¨å’Œæ—¥å¸¸ä½¿ç”¨ï¼Œç°åœ¨ä¸‹å•äº«å—ä¼˜æƒ ä»·æ ¼ã€‚",
            "voice_type": "professional"
        },
        {
            "name": "æ™ºèƒ½æ‰‹è¡¨",
            "description": "åŠŸèƒ½å¼ºå¤§çš„æ™ºèƒ½æ‰‹è¡¨ï¼Œå¥åº·ç›‘æµ‹ã€è¿åŠ¨è·Ÿè¸ªã€æ™ºèƒ½æé†’åº”æœ‰å°½æœ‰ã€‚æ—¶å°šè®¾è®¡ï¼Œå“è´¨ä¿è¯ã€‚",
            "voice_type": "friendly"
        }
    ]

    output_dir = Path("product_voiceovers")
    output_dir.mkdir(exist_ok=True)

    for i, product in enumerate(products, 1):
        print(f"\n[{i}/{len(products)}] Generating voiceover for: {product['name']}")

        # Create voice profile for this product
        voice_profile = tts_processor.create_product_voice_profile(
            language="zh",
            voice_type=product["voice_type"],
            gender="female"
        )

        # Generate filename
        safe_name = product["name"].replace(" ", "_")
        output_path = output_dir / f"{safe_name}_{product['voice_type']}.wav"

        # Synthesize
        await tts_processor.synthesize_text(
            text=product["description"],
            voice_profile=voice_profile,
            output_path=str(output_path)
        )

        print(f"  âœ… Generated: {output_path}")
        print(f"  ğŸ¤ Voice: {product['voice_type']} style")

    print(f"\nğŸ“Š Batch generation completed!")
    print(f"Generated {len(products)} voiceovers in: {output_dir}")


async def example_custom_voice_effects():
    """Demonstrate custom voice effects and modifications"""

    print("\nğŸ›ï¸ Custom Voice Effects Example")
    print("=" * 40)

    tts_processor = create_tts_processor()

    base_text = "æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„ç‰¹åˆ«ä¼˜æƒ æ´»åŠ¨ï¼è¿™é‡Œæœ‰æœ€å¥½çš„äº§å“å’Œæœ€ä¼˜çš„ä»·æ ¼ï¼"

    effects = [
        {"name": "æ­£å¸¸è¯­é€Ÿ", "speed": 1.0, "pitch": 1.0, "volume": 1.0},
        {"name": "å¿«é€Ÿæ’­æŠ¥", "speed": 1.3, "pitch": 1.1, "volume": 1.0},
        {"name": "æ…¢é€Ÿè¯¦è§£", "speed": 0.8, "pitch": 0.95, "volume": 1.0},
        {"name": "é«˜éŸ³è°ƒ", "speed": 1.0, "pitch": 1.2, "volume": 1.0},
        {"name": "ä½éŸ³è°ƒ", "speed": 1.0, "pitch": 0.8, "volume": 1.0},
        {"name": "å¤§éŸ³é‡", "speed": 1.0, "pitch": 1.0, "volume": 1.3},
    ]

    for effect in effects:
        print(f"\nğŸµ {effect['name']}")

        voice_profile = VoiceProfile(
            provider="edge",
            voice_name="zh-CN-XiaoxiaoNeural",
            language="zh-CN",
            gender="female",
            style="excited",
            speed=effect["speed"],
            pitch=effect["pitch"],
            volume=effect["volume"]
        )

        output_path = f"voice_effect_{effect['name']}.wav"

        await tts_processor.synthesize_text(
            text=base_text,
            voice_profile=voice_profile,
            output_path=output_path
        )

        print(f"  âœ… Generated: {output_path}")
        print(f"  âš™ï¸ Speed: {effect['speed']}, Pitch: {effect['pitch']}, Volume: {effect['volume']}")


async def example_tts_with_timing_analysis():
    """Analyze and optimize TTS timing for video content"""

    print("\nâ±ï¸ TTS Timing Analysis Example")
    print("=" * 40)

    # Simulate transcription segments with timing
    from src.ai_engine.speech_processor import TranscriptionSegment, TranscriptionResult

    segments = [
        TranscriptionSegment(start=0.0, end=3.5, text="æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„äº§å“å±•ç¤º", confidence=-0.1),
        TranscriptionSegment(start=4.0, end=8.2, text="è¿™æ¬¾äº§å“å…·æœ‰é©å‘½æ€§çš„åŠŸèƒ½", confidence=-0.05),
        TranscriptionSegment(start=9.0, end=12.5, text="ç°åœ¨è´­ä¹°äº«å—ç‰¹åˆ«ä¼˜æƒ ä»·æ ¼", confidence=-0.08),
        TranscriptionSegment(start=13.0, end=16.0, text="æ•°é‡æœ‰é™ï¼ŒæŠ“ç´§æ—¶é—´ä¸‹å•", confidence=-0.03),
    ]

    transcription = TranscriptionResult(
        segments=segments,
        language="zh",
        duration=16.0,
        full_text=" ".join([seg.text for seg in segments])
    )

    tts_processor = create_tts_processor()

    print("ğŸ“Š Original timing analysis:")
    total_chars = sum(len(seg.text) for seg in segments)
    total_time = transcription.duration

    print(f"  Total duration: {total_time:.1f}s")
    print(f"  Total characters: {total_chars}")
    print(f"  Average speaking rate: {total_chars/total_time:.1f} chars/second")

    print("\nğŸ¤ Creating optimized voiceover...")

    # Create voice profile optimized for the original timing
    voice_profile = VoiceProfile(
        provider="edge",
        voice_name="zh-CN-XiaoxiaoNeural",
        language="zh-CN",
        gender="female",
        style="professional",
        speed=1.0,  # Will be auto-adjusted
        pitch=1.0,
        volume=1.0
    )

    # Create voiceover with timing preservation
    output_path = "timing_optimized_voiceover.wav"
    await tts_processor.create_voiceover_from_transcription(
        transcription=transcription,
        voice_profile=voice_profile,
        output_path=output_path,
        preserve_timing=True,
        add_pauses=True
    )

    print(f"âœ… Timing-optimized voiceover: {output_path}")

    # Analyze new timing
    from pydub import AudioSegment
    audio = AudioSegment.from_wav(output_path)
    new_duration = len(audio) / 1000.0

    print(f"\nğŸ“ˆ Results:")
    print(f"  Original duration: {total_time:.1f}s")
    print(f"  New voiceover duration: {new_duration:.1f}s")
    print(f"  Time difference: {abs(new_duration - total_time):.1f}s")


async def main():
    """Run all examples"""

    print("ğŸ”Š AI Text-to-Speech Examples")
    print("=" * 50)

    print("\nğŸ“ Instructions:")
    print("1. Update file paths in examples as needed")
    print("2. Ensure you have internet connection for Edge TTS")
    print("3. Run: python example_text_to_speech.py")
    print("4. Or import and call specific example functions")

    print("\nğŸš€ Available Examples:")
    print("- example_basic_tts(): Simple text synthesis")
    print("- example_voice_styles(): Different voice styles")
    print("- example_voiceover_replacement(): Replace video audio")
    print("- example_multilingual_voiceover(): Multiple languages")
    print("- example_batch_voiceover_generation(): Batch processing")
    print("- example_custom_voice_effects(): Voice effects")
    print("- example_tts_with_timing_analysis(): Timing optimization")

    print("\nğŸ’¡ For Mac M1 Pro & Product Videos:")
    print("- Use Edge TTS for best quality")
    print("- Chinese: zh-CN-XiaoxiaoNeural (professional female)")
    print("- English: en-US-JennyNeural (clear female)")
    print("- Adjust speed: 0.9-1.1 for natural speech")
    print("- Use 'friendly' or 'professional' styles")

    print("\nğŸ¯ Optimization Tips:")
    print("- Match voice style to product type")
    print("- Use timing preservation for dubbing")
    print("- Test different speeds for target audience")
    print("- Add fade effects for smooth transitions")

    # Uncomment to run examples:
    # await example_basic_tts()
    # await example_voice_styles()
    # await example_voiceover_replacement()
    # await example_multilingual_voiceover()
    # await example_batch_voiceover_generation()
    # await example_custom_voice_effects()
    # await example_tts_with_timing_analysis()


if __name__ == "__main__":
    asyncio.run(main())